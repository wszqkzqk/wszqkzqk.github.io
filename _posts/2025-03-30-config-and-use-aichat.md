---
layout:     post
title:      é…ç½®å¹¶ä½¿ç”¨AIChat
subtitle:   åˆ©ç”¨å®‰è£…ä¾¿æ·ä¸”åŠŸèƒ½å¼ºå¤§çš„å‘½ä»¤è¡Œå·¥å…·ä¸LLM APIé«˜æ•ˆäº¤äº’
date:       2025-03-30
author:     wszqkzqk
header-img: img/llm/ai-bg-lossless.webp
catalog:    true
tags:       AI LLM å¼€æºè½¯ä»¶
---

## å‰è¨€

[**AIChat**](https://github.com/sigoden/aichat)æ˜¯ä¸€æ¬¾å¼€æºå‘½ä»¤è¡Œå¤§è¯­è¨€æ¨¡å‹å·¥å…·ï¼Œä¸»è¦ç”¨äºé«˜æ•ˆé›†æˆå’Œè°ƒç”¨å„ç±»AIæ¨¡å‹ã€‚å®ƒä»¥Rustç¼–å†™ï¼Œæ”¯æŒè·¨å¹³å°å®‰è£…ï¼Œå¹¶é€šè¿‡å¤šç§åŒ…ç®¡ç†å™¨æˆ–é¢„ç¼–è¯‘äºŒè¿›åˆ¶å¿«é€Ÿéƒ¨ç½²ã€‚å®ƒç»Ÿä¸€æ¥å…¥äº†20+ä¸»æµAIæœåŠ¡ï¼ˆå¦‚OpenAIã€Claudeã€Geminiç­‰ï¼‰ï¼Œæä¾›å¤šæ ·åŒ–äº¤äº’æ–¹å¼ï¼šç›´æ¥ç”ŸæˆShellå‘½ä»¤çš„CMDæ¨¡å¼ã€æ”¯æŒè‡ªåŠ¨è¡¥å…¨çš„äº¤äº’å¼REPLèŠå¤©ã€ç»“åˆå¤–éƒ¨æ–‡ä»¶çš„RAGå¢å¼ºé—®ç­”ï¼Œä»¥åŠé€šè¿‡å‡½æ•°è°ƒç”¨æ‰©å±•çš„è‡ªåŠ¨åŒ–å·¥å…·é“¾ã€‚ç‰¹è‰²åŠŸèƒ½åŒ…æ‹¬è§’è‰²é¢„è®¾ç®¡ç†ã€ä¼šè¯æŒä¹…åŒ–ã€å®å‘½ä»¤æ‰¹å¤„ç†ï¼Œå¹¶å†…ç½®è½»é‡HTTPæœåŠ¡ï¼Œå¯æœ¬åœ°éƒ¨ç½²APIæ¥å£å’ŒWebäº¤äº’ç•Œé¢ï¼ˆPlayground/Arenaï¼‰ã€‚ç”¨æˆ·å¯å®šåˆ¶ä¸»é¢˜å’Œæç¤ºæ¨¡æ¿ï¼Œé€‚åº”ä¸åŒå¼€å‘åœºæ™¯ã€‚é¡¹ç›®é‡‡ç”¨MIT/Apache 2.0åŒåè®®ï¼Œå…¼é¡¾å¼€å‘çµæ´»æ€§ä¸ç”Ÿäº§ç¯å¢ƒéœ€æ±‚ï¼Œæ˜¾è‘—æå‡AIæ¨¡å‹åœ¨å‘½ä»¤è¡Œç¯å¢ƒä¸‹çš„å®ç”¨æ€§å’Œæ•ˆç‡ã€‚

## å®‰è£…

Arch Linuxä¸Windowsçš„MSYS2å‡å·²ç»å®˜æ–¹æ”¶å½•äº†AIChatï¼Œç”¨æˆ·å¯ä»¥ç›´æ¥ä½¿ç”¨åŒ…ç®¡ç†å™¨è¿›è¡Œå®‰è£…ã€‚

### Arch Linux

```bash
sudo pacman -S aichat
```

### Windows

ç¬”è€…åœ¨2025.03.30ä¸ºWindowsçš„MSYS2ç¯å¢ƒå¢åŠ äº†`mingw-w64-aichat`åŒ…ï¼Œå¹¶åœ¨åŒæ—¥[è¢«MSYS2é¡¹ç›®æ¥å—](https://github.com/msys2/MINGW-packages/commit/2272a99a9c1175695017d8591c05d4e217613cc3)ï¼Œç°å·²æ”¯æŒç›´æ¥ä»MSYS2çš„å®˜æ–¹è½¯ä»¶æºå®‰è£…ã€‚åœ¨ç¡®ä¿Windowsç³»ç»Ÿå®‰è£…MSYS2åï¼Œæ‰“å¼€MSYS2ç»ˆç«¯ï¼ˆä»¥UCRT64ç¯å¢ƒä¸ºä¾‹ï¼‰ï¼Œæ‰§è¡Œä»¥ä¸‹å‘½ä»¤ï¼š

```bash
pacman -S mingw-w64-ucrt-x86_64-aichat
```

## APIé…ç½®

æˆ‘ä»¬å¯ä»¥åœ¨å„å¤§LLM APIæä¾›å•†å¤„ç”³è¯·APIå¯†é’¥ã€‚è¯·æ³¨æ„ï¼ŒAPIå¯†é’¥æ˜¯éå¸¸é‡è¦çš„å‡­è¯ï¼Œè¯·ä¸è¦æ³„éœ²ã€‚

é¦–æ¬¡è¿è¡ŒAIChatæ—¶ï¼Œç³»ç»Ÿä¼šæç¤ºæˆ‘ä»¬é…ç½®ï¼ŒåŒ…æ‹¬é€‰æ‹©æ¨¡å‹æœåŠ¡å•†ã€è¾“å…¥APIå¯†é’¥ç­‰ã€‚æˆ‘ä»¬å¯ä»¥é€‰æ‹©Google Geminiä½œä¸ºæ¨¡å‹æœåŠ¡å•†ï¼Œå¹¶è¾“å…¥ç”³è¯·åˆ°çš„APIå¯†é’¥ï¼Œç„¶ååˆ™éœ€è¦é€‰æ‹©æˆ‘ä»¬æƒ³è¦ä½¿ç”¨çš„æ¨¡å‹ã€‚é…ç½®å®Œæˆåï¼ŒAIChatä¼šè‡ªåŠ¨ä¿å­˜è®¾ç½®ã€‚é»˜è®¤çš„é…ç½®è¿‡ç¨‹ååˆ†ç®€å•ï¼Œ**ä¸€è·¯å®Œæˆä¹‹åå°±å¯ä»¥ç›´æ¥è¿è¡ŒAIChat**ï¼Œæ— éœ€å†æ¬¡é…ç½®ã€‚

å¦‚æœæˆ‘ä»¬è¿˜æƒ³è¦æ·»åŠ å¤šä¸ªæ¨¡å‹æœåŠ¡å•†ï¼Œå¯ä»¥åœ¨é…ç½®æ–‡ä»¶ä¸­æ‰‹åŠ¨æ·»åŠ ã€‚é…ç½®æ–‡ä»¶ä½äºç”¨æˆ·æ•°æ®ç›®å½•ä¸‹çš„`aichat/config.yaml`ï¼ˆåœ¨Linuxä¸Šé»˜è®¤ä¸º`~/.config/aichat/config.yaml`ï¼Œåœ¨Windowsä¸Šé»˜è®¤ä¸º`%APPDATA%\aichat\config.yaml`ï¼‰ã€‚

æ­¤å¤–ï¼ŒAIChaté»˜è®¤çš„ä¸Šä¸‹æ–‡å‹ç¼©é˜ˆå€¼è¾ƒå°ï¼Œä¸º`4000`ï¼Œç°åœ¨æ¯”è¾ƒå¼ºå¤§çš„å¤§æ¨¡å‹æ™®éæ”¯æŒ128 KåŠä»¥ä¸Šçš„ä¸Šä¸‹æ–‡ï¼Œæˆ‘ä»¬å°†é˜ˆå€¼è®¾å®šä¸º`100000`ä¸€èˆ¬æ˜¯åˆç†çš„ã€‚ç¬”è€…åœ¨ä¸€èˆ¬èŠå¤©ä¸­æ›´å–œæ¬¢ä½¿ç”¨DeepSeek v3 0324æ¨¡å‹ï¼ˆGoogle Gemini 2.5 Proéå¸¸å¼ºå¤§ä½†æ˜¯è¿‘æœŸOpenRouteræä¾›çš„Google Gemini 2.5 Proæœ‰æ—¶å€™å®¹æ˜“æ— å“åº”ï¼‰ï¼Œä»¥ä¸‹æ˜¯ç¬”è€…çš„ç¤ºä¾‹é…ç½®æ–‡ä»¶ï¼š

```yaml
compress_threshold: 100000

model: chutes:deepseek-ai/DeepSeek-V3-0324
clients:
- type: gemini
  api_key: xxxxxx
- type: openai-compatible
  name: openrouter
  api_base: https://openrouter.ai/api/v1
  api_key: xxxxxx
  models:
    # Deepseek
    - name: deepseek/deepseek-chat-v3-0324:free
      max_input_tokens: 131072
      max_output_tokens: 131072
      supports_function_calling: true
    - name: deepseek/deepseek-r1:free
      max_input_tokens: 163840
      max_output_tokens: 163840
    # Google Gemini
    - name: google/gemini-2.5-pro-exp-03-25:free
      max_input_tokens: 1000000
      max_output_tokens: 65536
      supports_vision: true
      supports_function_calling: true
- type: openai-compatible
  name: chutes
  api_base: https://llm.chutes.ai/v1
  api_key: xxxxxx
  models:
    # DeepSeek
    - name: deepseek-ai/DeepSeek-V3-0324
      max_input_tokens: 131072
      max_output_tokens: 131072
      supports_function_calling: true
    - name: deepseek-ai/DeepSeek-R1
      max_input_tokens: 163840
      max_output_tokens: 163840
    # Meta
    - name: chutesai/Llama-4-Maverick-17B-128E-Instruct-FP8
      max_input_tokens: 1000000
      max_output_tokens: 256000
      supports_vision: true
```

## ä½¿ç”¨

ç®€å•è¿è¡ŒAIChatï¼š

```bash
aichat
```

è¿›å…¥AIChatåï¼Œæˆ‘ä»¬è¿˜å¯ä»¥ä½¿ç”¨å¾ˆå¤šå‘½ä»¤ï¼Œå¯ä»¥è¾“å…¥`.help`æŸ¥çœ‹ï¼š

```
.help                    Show this help guide
.info                    Show system info
.edit config             Modify configuration file
.model                   Switch LLM model
.prompt                  Set a temporary role using a prompt
.role                    Create or switch to a role
.info role               Show role info
.edit role               Modify current role
.save role               Save current role to file
.exit role               Exit active role
.session                 Start or switch to a session
.empty session           Clear session messages
.compress session        Compress session messages
.info session            Show session info
.edit session            Modify current session
.save session            Save current session to file
.exit session            Exit active session
.agent                   Use an agent
.starter                 Use a conversation starter
.edit agent-config       Modify agent configuration file
.info agent              Show agent info
.exit agent              Leave agent
.rag                     Initialize or access RAG
.edit rag-docs           Add or remove documents from an existing RAG
.rebuild rag             Rebuild RAG for document changes
.sources rag             Show citation sources used in last query
.info rag                Show RAG info
.exit rag                Leave RAG
.macro                   Execute a macro
.file                    Include files, directories, URLs or commands
.continue                Continue previous response
.regenerate              Regenerate last response
.copy                    Copy last response
.set                     Modify runtime settings
.delete                  Delete roles, sessions, RAGs, or agents
.exit                    Exit REPL

Type ::: to start multi-line editing, type ::: to finish it.
Press Ctrl+O to open an editor for editing the input buffer.
Press Ctrl+C to cancel the response, Ctrl+D to exit the REPL.
```

## åŸºç¡€ä¼šè¯ä½¿ç”¨

ä¾‹å¦‚ï¼Œå¦‚æœæˆ‘ä»¬éœ€è¦ä¿ç•™ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œå¯ä»¥ä½¿ç”¨`.session`å‘½ä»¤åˆ›å»ºä¸€ä¸ªä¼šè¯ï¼š

```bash
.session
```

å¦‚æœéœ€è¦æŒ‡å®šä¼šè¯åç§°ï¼Œå¯ä»¥ä½¿ç”¨`.session <name>`å‘½ä»¤ï¼š

```bash
.session my_session
```

è¿™æ—¶æˆ‘ä»¬å¯ä»¥è¾“å…¥é—®é¢˜ï¼ŒAIChatä¼šè‡ªåŠ¨å°†é—®é¢˜å‘é€ç»™æ¨¡å‹å¹¶è¿”å›ç»“æœã€‚æˆ‘ä»¬ä¹Ÿå¯ä»¥ä½¿ç”¨`.exit session`å‘½ä»¤é€€å‡ºä¼šè¯ã€‚

### æ ¸å¿ƒåŠŸèƒ½ï¼šChat-REPL
AIChat çš„æ ¸å¿ƒæ˜¯ Chat-REPLï¼ˆäº¤äº’å¼èŠå¤©ç¯å¢ƒï¼‰ï¼Œæä¾›ä»¥ä¸‹ç‰¹æ€§ï¼š
1. **Tab è‡ªåŠ¨è¡¥å…¨**ï¼š
   - è¾“å…¥ `.` åæŒ‰ Tab å¯è¡¥å…¨ REPL å‘½ä»¤ã€‚
   - è¾“å…¥ `.model` åæŒ‰ Tab å¯è¡¥å…¨èŠå¤©æ¨¡å‹ã€‚
   - è¾“å…¥ `.set <key>` åæŒ‰ Tab å¯è¡¥å…¨é…ç½®å€¼ã€‚

2. **å¤šè¡Œè¾“å…¥æ”¯æŒ**ï¼š
   - æŒ‰ `Ctrl+O` ç”¨å¤–éƒ¨ç¼–è¾‘å™¨ç¼–è¾‘å¤šè¡Œæ–‡æœ¬ï¼ˆæ¨èï¼‰ã€‚
   - ç›´æ¥ç²˜è´´å¤šè¡Œæ–‡æœ¬ï¼ˆéœ€ç»ˆç«¯æ”¯æŒï¼Œç¬”è€…åœ¨Linuxä¸‹ç”¨Konsoleæµ‹è¯•å‘ç°ç›´æ¥æ”¯æŒï¼ŒWindowsä¸‹ç”¨Windows Terminalåˆ™å‘ç°ä¸æ”¯æŒï¼‰ã€‚
   - è¾“å…¥ `:::` å¼€å§‹å¤šè¡Œç¼–è¾‘ï¼Œå†è¾“å…¥ `:::` ç»“æŸã€‚
   - ä½¿ç”¨å¿«æ·é”® `Ctrl/Shift/Alt + Enter` ç›´æ¥æ¢è¡Œã€‚

3. **å†å²è®°å½•æœç´¢**ï¼š
   - æŒ‰ `Ctrl+R` æœç´¢å†å²è®°å½•ï¼Œç”¨ `â†‘â†“` é”®å¯¼èˆªã€‚

4. **å¯é…ç½®é”®ç»‘å®š**ï¼š
   - æ”¯æŒ Emacs å’Œ VI é£æ ¼çš„é”®ç»‘å®šã€‚

5. **è‡ªå®šä¹‰æç¤ºç¬¦**ï¼š
   - å¯åœ¨æç¤ºç¬¦ä¸­æ˜¾ç¤ºå½“å‰ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚

## æ–‡ä»¶æ“ä½œ

AIChatæ”¯æŒæ–‡æœ¬ã€å›¾ç‰‡ã€PDFæ–‡æ¡£ç­‰å¤šç§æ–‡ä»¶ç±»å‹ï¼Œè¿˜æ”¯æŒä¼ å…¥URLå’Œç›®å½•ç­‰ã€‚å¦‚æœæˆ‘ä»¬éœ€è¦ä½¿ç”¨æ–‡ä»¶æ“ä½œï¼Œå¯ä»¥ä½¿ç”¨`.file`å‘½ä»¤ï¼š

```bash
.file /path/to/file
```

`.file`å‘½ä»¤è¿˜å¯ä»¥æŒ‡å®šå¤šä¸ªæ–‡ä»¶æˆ–ç›®å½•ï¼Œä½¿ç”¨ç©ºæ ¼åˆ†éš”ã€‚ä¾‹å¦‚ï¼š

```bash
.file /path/to/file1 /path/to/file2
```

åœ¨æŒ‡å®šå®Œæ–‡ä»¶åï¼Œå¦‚æœæˆ‘ä»¬è¿˜æƒ³è¦æŒ‡å®šæäº¤æ–‡ä»¶çš„è¿™è½®å¯¹è¯çš„æç¤ºè¯ï¼Œå¯ä»¥åœ¨å‘½ä»¤åé¢åŠ ä¸Š`--`ï¼Œç„¶ååœ¨åé¢è¾“å…¥æç¤ºè¯å³å¯ï¼š

```bash
.file /path/to/file -- è¯·å¸®æˆ‘æ€»ç»“ä¸€ä¸‹è¿™ä¸ªæ–‡ä»¶çš„å†…å®¹
```

æç¤ºè¯ä¸­è¿˜å¯ä»¥åŒ…å«å¯¹äºå¤šä¸ªæ–‡ä»¶çš„é«˜çº§æ“ä½œï¼Œä¾‹å¦‚ï¼š

```bash
.file a.txt b.txt -- æ‰¾å‡ºä¸åŒä¹‹å¤„
.file img1.png img2.png -- åˆ†æå›¾ç‰‡å·®å¼‚
```

å¦‚æœå·²ç»åœ¨ä¼šè¯ä¸­ï¼Œæˆ‘ä»¬è¿˜å¯ä»¥åç»­å¯¹æ–‡ä»¶çš„å†…å®¹è¿›è¡Œè¿›ä¸€æ­¥è¯¢é—®ã€‚å¾ˆå¤šæ—¶å€™ç½‘é¡µç‰ˆæˆ–è€…å®¢æˆ·ç«¯çš„LLMå¯èƒ½å¯¹æ–‡ä»¶ä¸Šä¼ å¤§å°æœ‰é™åˆ¶ï¼Œè€ŒAIChatç›´æ¥æŒ‡å®šæœ¬åœ°æ–‡ä»¶æ—¶ï¼Œæ–‡ä»¶ä¼šåœ¨æœ¬åœ°å¤„ç†è€Œæ— éœ€ä¸Šä¼ åˆ°è¿œç¨‹æœåŠ¡å™¨ï¼Œå› æ­¤**ä¸å—ç½‘é¡µç‰ˆå¤§æ¨¡å‹é€šå¸¸å­˜åœ¨çš„æ–‡ä»¶ä¸Šä¼ å¤§å°é™åˆ¶**ã€‚

### å¼•ç”¨ä¸Šä¸€ä¸ªå›å¤çš„å†…å®¹åˆ°æ–‡ä»¶ï¼š`%%`

`%%`æ˜¯`.file`å‘½ä»¤çš„ä¸€ä¸ªç‰¹æ®Šå‚æ•°ï¼Œåœ¨`.file`å‘½ä»¤ä¸­ä½¿ç”¨`%%`æ—¶ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨å°†ä¸Šä¸€æ¬¡AIçš„å›å¤å†…å®¹ä½œä¸ºè¾“å…¥ã€‚ä¾‹å¦‚ï¼š

```bash
.file %% -- å°†ä¸Šæ¬¡å›å¤ç¿»è¯‘æˆè‹±æ–‡
```

è¿™ç›¸å½“äºå°† AI çš„ä¸Šä¸€æ¡å›å¤ä¼ é€’ç»™åç»­æŒ‡ä»¤å¤„ç†ã€‚

åˆ©ç”¨`%%`ï¼Œæˆ‘ä»¬å¯ä»¥å®ç°å¤šæ­¥å¤„ç†çš„é“¾å¼æµç¨‹ï¼ˆå¦‚ç”Ÿæˆä»£ç åè¿­ä»£ä¼˜åŒ–ç­‰ï¼‰ã€‚

### è¯»å–å‘½ä»¤è¾“å‡ºï¼š``` `command` ```

æˆ‘ä»¬è¿˜å¯ä»¥ä½¿ç”¨åå¼•å· `` `command` `` æ¥è¯»å–å‘½ä»¤çš„è¾“å‡ºã€‚ä¾‹å¦‚ï¼š

```bash
.file `git diff HEAD` -- ç”Ÿæˆ Git æäº¤ä¿¡æ¯
```

è¿™é‡Œä¼šå…ˆæ‰§è¡Œ`git diff HEAD`ï¼Œå°†å…¶å·®å¼‚å†…å®¹å‘é€ç»™LLMè¿›è¡Œå¤„ç†ã€‚ä»¥ä¸Šç¤ºä¾‹å¯ä»¥ç”¨äºç”ŸæˆGitæäº¤ä¿¡æ¯ï¼Œå¯¹å¾ˆå¤šå¼ºè¿«ç—‡å¾ˆæœ‰ç”¨ã€‚

è€ƒè™‘åˆ°Gitæäº¤ä¿¡æ¯è¿˜å¾€å¾€éœ€è¦ç¬¦åˆé¡¹ç›®çš„å†å²é£æ ¼ï¼Œç¬”è€…æ›´æ¨èä½¿ç”¨ï¼š

```bash
.file `git diff HEAD` `git log -n 30` -- æ ¹æ®å†å²Gitæäº¤ä¿¡æ¯çš„é£æ ¼ï¼Œä¸ºæœ¬æ¬¡ä¿®æ”¹ç”ŸæˆGitæäº¤ä¿¡æ¯
```

è¿™é‡Œçš„`git diff HEAD`ä¼šå°†å½“å‰å·¥ä½œåŒºå’Œæš‚å­˜çš„å·®å¼‚å†…å®¹ä¼ é€’ç»™LLMï¼Œè€Œ`git log -n 30`ä¼šå°†è¿‘30æ¡é¡¹ç›®å†å²æäº¤ä¿¡æ¯ä¼ é€’ç»™LLMä½œä¸ºèŒƒä¾‹ã€‚è¿™æ ·ï¼ŒLLMå°±å¯ä»¥æ ¹æ®å†å²æäº¤ä¿¡æ¯çš„é£æ ¼æ¥ç”Ÿæˆç¬¦åˆé¡¹ç›®é£æ ¼çš„æäº¤ä¿¡æ¯ã€‚

## RAGå¢å¼ºé—®ç­”

RAGï¼ˆRetrieval-Augmented Generationï¼‰æ˜¯ä¸€ç§å¢å¼ºé—®ç­”çš„æŠ€æœ¯ï¼Œå®ƒç»“åˆäº†æ£€ç´¢å’Œç”Ÿæˆæ¨¡å‹çš„ä¼˜åŠ¿ã€‚AIChatæ”¯æŒRAGåŠŸèƒ½ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨`.rag`å‘½ä»¤æ¥åˆå§‹åŒ–æˆ–è®¿é—®RAGã€‚ä¾‹å¦‚ï¼Œå¦‚æœæˆ‘ä»¬æƒ³è¦åŸºäºAIChatçš„Wikiæ–‡æ¡£è¿›è¡Œå¢å¼ºé—®ç­”ï¼Œå¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤ï¼š

```bash
.rag aichat-wiki
```

åœ¨è¿è¡Œ`.rag`å‘½ä»¤åï¼ŒAIChatä¼šè¦æ±‚æˆ‘ä»¬æŒ‡å®šEmbeddingæ¨¡å‹å¹¶è®¾ç½®ç›¸å…³å‚æ•°ï¼ˆå¯ä»¥ä¿ç•™é»˜è®¤å€¼ï¼‰ã€‚å‡è®¾æˆ‘ä»¬ä¹‹å‰æ·»åŠ äº†Google Geminiçš„APIå¯†é’¥ï¼Œæˆ‘ä»¬å°±å¯ä»¥ä½¿ç”¨Googleçš„Embeddingæ¨¡å‹æ¥è¿›è¡ŒRAGå¢å¼ºé—®ç­”ã€‚

è®¾ç½®å®Œæ¨¡å‹ä»¥åï¼ŒAIChatè¿˜æ˜¯è¦æ±‚æˆ‘ä»¬è®¾ç½®RAGçš„å†…å®¹æºï¼Œå¯¹äºAIChatçš„Wikiæ–‡æ¡£ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨`https://github.com/sigoden/aichat/wiki/**`ä½œä¸ºå†…å®¹æºï¼Œå…¶ä¸­`**`è¡¨ç¤ºé€’å½’åŒ¹é…è¯¥ç›®å½•ä¸‹çš„æ‰€æœ‰æ–‡ä»¶å’Œå­ç›®å½•ï¼Œå°†AIChat Wikiçš„æ‰€æœ‰é¡µé¢æ·»åŠ åˆ°RAGä¸­ã€‚å¦å¤–ï¼Œå¦‚æœéœ€è¦åŒæ—¶æŒ‡å®šå¤šä¸ªç‹¬ç«‹çš„URLï¼Œå¯ä»¥ç”¨åˆ†å· `;` åˆ†éš”å®ƒä»¬ã€‚

å¦‚æœä½¿ç”¨ä¸Šè¿°è®¾å®šï¼Œæˆ‘ä»¬å³å¯é…ç½®å¾—åˆ°ä¸€ä¸ªRAGå¢å¼ºé—®ç­”çš„ç¯å¢ƒï¼š

```log
> .rag aichat-wiki
âš™ Initializing RAG...
> Select embedding model: gemini:text-embedding-004 (max-tokens:2048;max-batch:100;price:0)
> Set chunk size: 1500
> Set chunk overlay: 75
> Add documents: https://github.com/sigoden/aichat/wiki/**
Load https://github.com/sigoden/aichat/wiki/** [1/1]
Start crawling url=https://github.com/sigoden/aichat/wiki/ exclude=_history extract=#wiki-body
Crawled https://github.com/sigoden/aichat/wiki/
Crawled https://github.com/sigoden/aichat/wiki/Environment-Variables
Crawled https://github.com/sigoden/aichat/wiki/Macro-Guide
Crawled https://github.com/sigoden/aichat/wiki/Role-Guide
Crawled https://github.com/sigoden/aichat/wiki/Command-Line-Guide
Crawled https://github.com/sigoden/aichat/wiki/Custom-Theme
Crawled https://github.com/sigoden/aichat/wiki/Custom-REPL-Prompt
Crawled https://github.com/sigoden/aichat/wiki/FAQ
Crawled https://github.com/sigoden/aichat/wiki/Chat-REPL-Guide
Crawled https://github.com/sigoden/aichat/wiki/Configuration-Guide
Crawled https://github.com/sigoden/aichat/wiki/RAG-Guide
```

å®Œæˆä»¥åï¼Œæˆ‘ä»¬å³å¯åœ¨æ­¤RAGç¯å¢ƒä¸­è¿›è¡Œå¢å¼ºé—®ç­”ã€‚

åœ¨RAGç¯å¢ƒä¸­ï¼Œæˆ‘ä»¬è¿˜å¯ä»¥å åŠ ä½¿ç”¨`.session`å‘½ä»¤æ¥åˆ›å»ºä¼šè¯ï¼Œä»¥ä¾¿æ¨¡å‹èƒ½å¤Ÿè®°ä½å¯¹è¯å†…å®¹ã€‚

æ­¤å¤–ï¼Œæˆ‘ä»¬åœ¨RAGä¸­å¯¹äºæ¨¡å‹çš„éœ€æ±‚å¾€å¾€ä¸æ™®é€šä¼šè¯ä¸åŒï¼ŒRAGä¸­æˆ‘ä»¬å¾€å¾€éœ€è¦è¦æ±‚æ¨¡å‹çš„å¹»è§‰ç‡å°½å¯èƒ½åœ°ä½ï¼Œå¯ä»¥å‚è€ƒé™„å½•çš„[æ¦œå•](#æ¨¡å‹å¹»è§‰ç‡æ¦œå•)æ¥é€‰æ‹©åˆé€‚çš„æ¨¡å‹ã€‚

## å†…ç½®HTTPæœåŠ¡å™¨

å¯åŠ¨æœ¬åœ°æœåŠ¡ï¼š

```
aichat --serve
```

é»˜è®¤åœ°å€ä¸º `http://127.0.0.1:8000`ï¼Œæä¾›ä»¥ä¸‹ç«¯ç‚¹ï¼š
- èŠå¤©è¡¥å…¨ APIï¼š`/v1/chat/completions`
- åµŒå…¥ APIï¼š`/v1/embeddings`
- LLM  playground å’Œç«æŠ€åœºã€‚

æ”¯æŒè‡ªå®šä¹‰ç›‘å¬åœ°å€å’Œç«¯å£ï¼š

```
aichat --serve 127.0.0.1:1234
```

å¦‚æœæƒ³è¦åœ¨AIChatæä¾›çš„HTTPæœåŠ¡ä¸­ç›´æ¥ä¸LLMäº¤äº’ï¼Œå¯ä»¥æ‰“å¼€è¿è¡Œ`aichat --serve`æ‰€è¾“å‡ºçš„`LLM Playground`çš„é“¾æ¥ï¼ˆä¾‹å¦‚`http://127.0.0.1:8000/playground`ï¼‰ï¼Œåœ¨è¿™é‡Œæˆ‘ä»¬å¯ä»¥ç›´æ¥ä¸LLMè¿›è¡Œäº¤äº’ã€‚

|[![#~/img/llm/aichat-http-serve.webp](/img/llm/aichat-http-serve.webp)](/img/llm/aichat-http-serve.webp)|
|:----:|
|åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€AIChatç®€æ´çš„HTTPæœåŠ¡ç•Œé¢|

AIChatçš„ç½‘é¡µç‰ˆé»˜è®¤ä¼šè¿è¡Œåœ¨ä¸€ä¸ªä¸ä¿å­˜çš„ä¼šè¯ä¸­ï¼Œç‚¹å‡»å·¦ä¸Šè§’çš„`+`å›¾æ ‡å¯ä»¥åˆ›å»ºä¸€ä¸ªæ–°çš„ä¼šè¯ã€‚ä¸è¿‡ç¬”è€…æ²¡æœ‰æ‰¾åˆ°åœ¨ç½‘é¡µä¸­ä¿å­˜ä¼šè¯çš„åŠŸèƒ½ï¼Œç½‘é¡µç‰ˆä¸­çš„æ‰€æœ‰ä¼šè¯ä¼¼ä¹ä¼šåœ¨**åœæ­¢æœåŠ¡**åä¸¢å¤±ã€‚

## Shellé›†æˆ

åœ¨è¿è¡Œ`aichat`å‘½ä»¤æ—¶åŠ ä¸Š`-e`å‚æ•°å¯ä»¥è®©AIç”Ÿæˆå¹¶æ‰§è¡Œå‘½ä»¤ï¼ˆéœ€ç¡®è®¤ï¼‰ã€‚ä¾‹å¦‚ï¼š

```bash
aichat -e "å®‰è£…docker"  # ç”Ÿæˆé€‚åˆå½“å‰ç³»ç»Ÿçš„å®‰è£…å‘½ä»¤
```

ç”Ÿæˆå‘½ä»¤åï¼Œç³»ç»Ÿä¼šè¯¢é—®æ¥ä¸‹æ¥çš„æ“ä½œï¼š

```log
> aichat -e 'ä¸é€’å½’åœ°æ‰¾åˆ°/tmpä¸‹æ‰€æœ‰çš„pngæ–‡ä»¶å¹¶è½¬åŒ–ä¸ºæ— æŸçš„webp'
find /tmp -maxdepth 1 -name "*.png" -exec bash -c 'for f; do cwebp -lossless "$f" -o "${f%.*}.webp"; done' _ {} +
> execute | revise | describe | copy | quit:
```

æˆ‘ä»¬å¯ä»¥é€‰æ‹©æ‰§è¡Œã€ä¿®æ­£ã€æè¿°ã€å¤åˆ¶æˆ–é€€å‡ºã€‚é€‰æ‹©æ‰§è¡Œåï¼ŒAIChatä¼šè‡ªåŠ¨æ‰§è¡Œç”Ÿæˆçš„å‘½ä»¤ã€‚

## åº”ç”¨æ¡ˆä¾‹

ç¬”è€…æ˜¯Arch Linux for Loong64ï¼ˆLoong Arch Linuxï¼‰å‘è¡Œç‰ˆçš„ç»´æŠ¤è€…ï¼Œå¸¸å¸¸éœ€è¦åœ¨å¼€å‘è€…ç¤¾åŒºçš„æ—¥å¸¸ä¼šè®®ä¸Šå‘å…¶ä»–å¼€å‘è€…ä»‹ç»Loong Arch Linuxçš„æœ€æ–°è¿›å±•ã€‚ä¸ºäº†æé«˜ä¼šè®®æ•ˆç‡ï¼Œå¯ä»¥å¾ˆæ–¹ä¾¿åœ°ä½¿ç”¨AIChatæ¥ç”Ÿæˆè¿›åº¦ä¿¡æ¯æ±‡æ€»ã€‚æˆ‘ä»¬å¯ä»¥åˆ©ç”¨ä¹‹å‰ä»‹ç»çš„``` `command` ```çš„æ–¹å¼ï¼Œé€šè¿‡`git`å‘½ä»¤ï¼Œå°†è¿‘2å‘¨å†…çš„ä»“åº“æäº¤ä¿¡æ¯ä¼ é€’ç»™LLM,å¹¶è®©LLMä»**è¿™ä¸€ä¸ªè§’åº¦**æ¥å¸®åŠ©æ’°å†™æˆ‘ä»¬æ‰€éœ€è¦çš„æ±‡æŠ¥å†…å®¹ã€‚åœ¨AIChatçš„Chat-REPL CLIç•Œé¢ä¸­è¾“å…¥ï¼š

```bash
.file `git -C ~/projects/loongarch-packages/ log --since="2 weeks ago" --stat` -- å‡å¦‚ä½ æ˜¯Arch Linux for Loong64ç¤¾åŒºï¼ˆç”±åŒ—äº¬å¤§å­¦å­¦ç”ŸLinuxä¿±ä¹éƒ¨ç»´æŠ¤ï¼Œä»“åº“åœ°å€ä¸ºhttps://github.com/lcpu-club/loongarch-packagesï¼‰çš„ç»´æŠ¤è€…ï¼Œä½ éœ€è¦å‘å…¶ä»–é¾™æ¶æ„çš„å¼€å‘è€…æ±‡æŠ¥æœ€è¿‘ä¸¤å‘¨çš„Loong Arch Linuxå‘è¡Œç‰ˆçš„å¼€å‘ä¿¡æ¯ã€‚è¯·ä½ å…ˆä»gitä»“åº“çš„æäº¤è®°å½•ä¸­åˆ†æï¼Œç­›é€‰å¹¶è¯¦ç»†æ€»ç»“å‡ºå¯¹å…¶ä»–å¼€å‘è€…å’Œæˆ‘ä»¬çš„ç”¨æˆ·æœ‰å‚è€ƒæ„ä¹‰ï¼Œå°¤å…¶æ˜¯å¯¹å…¶ä»–å‘è¡Œç‰ˆå’Œä¸Šæ¸¸å¼€å‘è€…ï¼ˆæŒ‡å‚ä¸é¾™æ¶æ„ç›¸å…³å¼€å‘çš„ä¸Šæ¸¸å¼€å‘è€…ï¼‰çš„ç»´æŠ¤æœ‰æ½œåœ¨å¸®åŠ©çš„å†…å®¹ã€‚è¯·æœ‰é€‰æ‹©åœ°ä»‹ç»ï¼Œä½†æ˜¯åˆ‡å‹¿é—æ¼é‡è¦ã€æœ‰ä»·å€¼çš„ä¿¡æ¯ï¼›è¯·ç”¨æ‹¬å·æ ‡æ³¨å‡ºä¿®å¤çš„è´¡çŒ®è€…ï¼Œä¾‹å¦‚(by wszqkzqk)è¿™ç§å½¢å¼ï¼›è¯·å°½é‡é™„ä¸Šç›¸å…³æäº¤çš„é“¾æ¥ï¼ˆå¦‚æœæœ‰å¯¹åº”PRï¼Œä¼˜å…ˆæ”¾PRé“¾æ¥è€Œä¸æ˜¯å†—é•¿çš„commité“¾æ¥ï¼‰å’Œå‘ä¸Šæ¸¸è´¡çŒ®å†…å®¹çš„é“¾æ¥ä¾›å‚è€ƒ
```

è¿™é‡Œçš„`git -C ~/projects/loongarch-packages/ log --since="2 weeks ago" --stat`ä¼šå°†æœ€è¿‘ä¸¤å‘¨çš„æäº¤è®°å½•ç›´æ¥ä¼ é€’ç»™LLMè¿›è¡Œå¤„ç†ã€‚LLMä¼šè‡ªåŠ¨åˆ†ææäº¤è®°å½•ï¼Œå¹¶ç”Ÿæˆä¸€ä»½è¯¦ç»†çš„è¿›åº¦ä¿¡æ¯æ±‡æ€»ï¼Œä¾‹å¦‚ç¬”è€…åœ¨2025.04.10æ—¶çš„è¿è¡Œç»“æœï¼š

```markdown
ä»¥ä¸‹æ˜¯ä»æœ€è¿‘ä¸¤å‘¨çš„æäº¤è®°å½•ä¸­ç­›é€‰å‡ºçš„å¯¹LoongArch Linuxå‘è¡Œç‰ˆå¼€å‘æœ‰é‡è¦å‚è€ƒä»·å€¼çš„å†…å®¹æ€»ç»“ï¼Œç‰¹åˆ«å…³æ³¨å¯¹å…¶ä»–å‘è¡Œç‰ˆå’Œä¸Šæ¸¸å¼€å‘è€…æœ‰å¸®åŠ©çš„ä¿¡æ¯ï¼š

---

### 1. **AMDVLKé©±åŠ¨æ”¯æŒ**
- **æäº¤**: [a0d186c](https://github.com/lcpu-club/loongarch-packages/commit/a0d186ca279b47434b2a1c902a3247dbe379e73b)  
  - ç§»æ¤äº†ä¸Šæ¸¸stbåº“çš„LoongArchæ”¯æŒè¡¥ä¸ï¼ˆ[stb#1610](https://github.com/nothings/stb/pull/1610)ï¼‰(by wszqkzqk)  
  - ä¸´æ—¶æ·»åŠ `-DCMAKE_POLICY_VERSION_MINIMUM=3.5`ä»¥è§£å†³æ„å»ºé—®é¢˜ï¼ˆ[AMDVLK#402](https://github.com/GPUOpen-Drivers/AMDVLK/issues/402)ï¼‰ã€‚  
  - **æ„ä¹‰**: ä¸ºLoongArchæä¾›äº†AMD GPUçš„å¼€æºVulkané©±åŠ¨æ”¯æŒï¼Œå¯¹å…¶ä»–å‘è¡Œç‰ˆé›†æˆAMDVLKæœ‰å‚è€ƒä»·å€¼ã€‚

---

### 2. **Rustç”Ÿæ€é€‚é…**
- **æäº¤**: [4a56a27](https://github.com/lcpu-club/loongarch-packages/commit/4a56a27961b0aa4b85e3f75c4ac8813f8f55cd09)  
  - ä¿®å¤`aichat`çš„ä¾èµ–`hnsw_rs`ï¼Œæ›¿æ¢`mmap-rs`ä¸º`memmap2`ä»¥è§£å†³æ„å»ºé—®é¢˜ (by wszqkzqk)ã€‚  
  - ä¸Šæ¸¸PR: [hnswlib-rs#23](https://github.com/jean-pierreBoth/hnswlib-rs/pull/23)ã€‚  
- **æäº¤**: [3d9a05e](https://github.com/lcpu-club/loongarch-packages/commit/3d9a05e1cf89598b581106c6b0329ee32b836aae)  
  - ä¿®å¤`arti`ï¼ˆTorå®¢æˆ·ç«¯ï¼‰çš„`aws-lc-sys`æ„å»ºé—®é¢˜ï¼Œéœ€æ·»åŠ `cmake`å’Œ`clang`ä¾èµ– (by wszqkzqk)ã€‚  
  - ä½¿ç”¨`mold`é“¾æ¥å™¨ç»•è¿‡`bfd`çš„åˆ†æ®µé”™è¯¯é—®é¢˜ã€‚  
  - **æ„ä¹‰**: å±•ç¤ºäº†Rustå·¥å…·é“¾åœ¨LoongArchä¸Šçš„å¸¸è§é—®é¢˜åŠè§£å†³æ–¹æ¡ˆï¼Œå¯¹ä¸Šæ¸¸Ruståº“ç»´æŠ¤è€…æœ‰å‚è€ƒä»·å€¼ã€‚

---

### 3. **QEMUè™šæ‹ŸåŒ–æ”¹è¿›**
- **æäº¤**: [4e2b778](https://github.com/lcpu-club/loongarch-packages/commit/4e2b77892556eaa06dead178b570ab17fb09bc73)  
  - ä¸º`qemu-system-loongarch64`æ·»åŠ `edk2-loongarch64`ä¾èµ–ï¼ˆç±»ä¼¼x86/aarch64ï¼‰(by wszqkzqk)ã€‚  
  - **æ„ä¹‰**: å®Œå–„äº†LoongArchè™šæ‹ŸåŒ–æ”¯æŒï¼Œä¸ºå…¶ä»–å‘è¡Œç‰ˆæä¾›æ ‡å‡†åŒ–ä¾èµ–é…ç½®å‚è€ƒã€‚

---

### 4. **Chromium/Electroné‡å¤§æ›´æ–°**
- **æäº¤**: [ce1141a](https://github.com/lcpu-club/loongarch-packages/commit/ce1141a710fd571cf05c75913474ceb6b3bdc79f)  
  - å‡çº§è‡³Electron 35/Chromium 134ï¼Œä¿®å¤Swiftshaderçš„LLVM16å…¼å®¹æ€§é—®é¢˜ (by wszqkzqk)ã€‚  
  - åŒ…å«å¤§é‡LoongArchæ”¯æŒè¡¥ä¸ï¼ˆå¦‚seccompä¿®å¤ã€depot_toolsé€‚é…ç­‰ï¼‰ã€‚  
- **æäº¤**: [2b0c6c4](https://github.com/lcpu-club/loongarch-packages/commit/2b0c6c499d26e220c15ab050389106ea4ac59251)  
  - Chromium 135å‡çº§ï¼Œä¸å†éœ€è¦Swiftshaderçš„é¢å¤–è¡¥ä¸ (by wszqkzqk)ã€‚  
  - **æ„ä¹‰**: ä¸ºæµè§ˆå™¨ç”Ÿæ€çš„LoongArchæ”¯æŒæä¾›æŒç»­ç»´æŠ¤èŒƒä¾‹ï¼Œè¡¥ä¸å¯åé¦ˆè‡³ä¸Šæ¸¸Chromiumã€‚

---

### 5. **Qt6 WebEngineé€‚é…**
- **æäº¤**: [f75364e](https://github.com/lcpu-club/loongarch-packages/commit/f75364e1cef6295b0b75df70134b661835eda9de)  
  - å‡çº§è‡³Qt 6.9ï¼Œç§»é™¤å·²åˆå¹¶çš„`libyuv`è¡¥ä¸ï¼ˆä¸Šæ¸¸å·²ä¿®å¤ï¼‰(by wszqkzqk)ã€‚  
  - **æ„ä¹‰**: å±•ç¤ºäº†å¦‚ä½•ä¸ä¸Šæ¸¸åä½œé€æ­¥å‡å°‘ä¸‹æ¸¸è¡¥ä¸ï¼Œæ¨åŠ¨ä»£ç åˆå¹¶ã€‚

---

### 6. **LuaJITå…³é”®ä¿®å¤**
- **æäº¤**: [00fd5f7](https://github.com/lcpu-club/loongarch-packages/commit/00fd5f75bbebdc807594ccdc364756da36073dbf)  
  - ä¿®å¤LuaJITçš„JITç¼–è¯‘é—®é¢˜ï¼Œç¡®ä¿LazyVimç­‰å·¥å…·é“¾å…¼å®¹æ€§ (by Wu Xiaotian)ã€‚  
- **æäº¤**: [b7dca15](https://github.com/lcpu-club/loongarch-packages/commit/b7dca1539e9c3f6ab39ab04bf9b6e105863ef804)  
  - åˆå¹¶é¾™èŠ¯ç¤¾åŒºçš„LuaJITæ›´æ–°ï¼Œæ”¯æŒNeoVimæ„å»º (by Pluto Yang)ã€‚  
  - **æ„ä¹‰**: è§£å†³äº†åŠ¨æ€è¯­è¨€è¿è¡Œæ—¶çš„é‡è¦å…¼å®¹æ€§é—®é¢˜ï¼Œè¡¥ä¸å¯åé¦ˆè‡³LuaJITä¸Šæ¸¸ã€‚

---

### 7. **å·¥å…·é“¾ä¼˜åŒ–**
- **æäº¤**: [659066f](https://github.com/lcpu-club/loongarch-packages/commit/659066f434f0d81b9c95ba23a7e13bef6b95733c)  
  - ä¿®å¤`pkgfile`çš„LoongArch64æ¶æ„è¯†åˆ«é—®é¢˜ (by wszqkzqk)ã€‚  
  - **æ„ä¹‰**: æ”¹è¿›åŒ…ç®¡ç†å·¥å…·å¯¹LoongArchçš„æ”¯æŒï¼Œå»ºè®®æäº¤è‡³Arch Linuxä¸Šæ¸¸ã€‚

---

### 8. **ä¸Šæ¸¸è´¡çŒ®å»ºè®®**
- **å·²åˆå¹¶ä¸Šæ¸¸çš„è¡¥ä¸**:  
  - `libyuv`ï¼ˆQt6ä¾èµ–ï¼‰çš„LoongArch SIMDæ”¯æŒå·²åˆå¹¶ï¼Œå¯ç§»é™¤æœ¬åœ°è¡¥ä¸ã€‚  
  - `stb`åº“çš„LoongArchè¡¥ä¸ï¼ˆ[stb#1610](https://github.com/nothings/stb/pull/1610)ï¼‰å·²åˆå¹¶ã€‚  
- **å¾…æ¨åŠ¨çš„è¡¥ä¸**:  
  - `hnsw_rs`çš„`memmap2`æ›¿æ¢ï¼ˆ[hnswlib-rs#23](https://github.com/jean-pierreBoth/hnswlib-rs/pull/23)ï¼‰éœ€ä¸Šæ¸¸å®¡æ ¸ã€‚  
  - `pkgfile`çš„æ¶æ„è¯†åˆ«è¡¥ä¸å¯æäº¤è‡³Arch Linuxã€‚

---

### å®Œæ•´æäº¤åˆ—è¡¨
- [æ‰€æœ‰ç›¸å…³æäº¤è®°å½•](https://github.com/lcpu-club/loongarch-packages/commits/main)  
- **é‡ç‚¹åŒ…**: AMDVLKã€QEMUã€Chromium/Electronã€Qt6ã€LuaJITã€Rustç”Ÿæ€å·¥å…·ã€‚

---

ä»¥ä¸Šå†…å®¹å¯ä¾›å…¶ä»–LoongArchå‘è¡Œç‰ˆç»´æŠ¤è€…å’Œä¸Šæ¸¸å¼€å‘è€…å‚è€ƒï¼Œæ¬¢è¿è¿›ä¸€æ­¥åä½œä¼˜åŒ–ç”Ÿæ€æ”¯æŒï¼
```

LLMç”Ÿæˆçš„ä¿¡æ¯æœªå¿…ç›´æ¥å¯ç”¨ï¼Œå¯èƒ½ä¼šæœ‰**é”™è¯¯ã€é—æ¼æˆ–è€…ä¸æ­£ç¡®çš„è§£è¯»**ï¼ˆè¿™åœ¨ä¸Šé¢çš„ç¤ºä¾‹ä¸­å³å­˜åœ¨ï¼‰ï¼Œä½†æ˜¯ç¡®å®å¯ä»¥å¸®åŠ©æˆ‘ä»¬å¿«é€Ÿç”Ÿæˆä¸€ä»½å¤§è‡´çš„è¿›åº¦ä¿¡æ¯ã€‚æˆ‘ä»¬å¯ä»¥åœ¨æ­¤åŸºç¡€ä¸Šè¿›è¡Œä¿®æ”¹å’Œè¡¥å……ï¼Œæœ€ç»ˆå½¢æˆä¸€ä»½å®Œæ•´çš„è¿›åº¦ä¿¡æ¯ã€‚

å¦å¤–ï¼Œéœ€è¦æ³¨æ„çš„æ˜¯ï¼Œç¤¾åŒºçš„ä¿¡æ¯ä¸ä»…ä»…æ˜¯ä»£ç çš„æäº¤ä¿¡æ¯ï¼Œå¾ˆå¤šæ—¶å€™æˆ‘ä»¬è¿˜éœ€è¦å…³æ³¨ç¤¾åŒºçš„å…¶ä»–åŠ¨æ€ï¼Œä¾‹å¦‚ç¤¾åŒºæˆå‘˜çš„è®¨è®ºï¼Œä»¥åŠæ ¸å¿ƒæˆå‘˜åœ¨ä¸Šæ¸¸çš„æäº¤ç­‰ã€‚æˆ‘ä»¬ä¸èƒ½å¯„å¸Œæœ›ä½¿ç”¨AIChatçš„ä¸€æ¡å‘½ä»¤å°±èƒ½å®Œæˆæ‰€æœ‰çš„å·¥ä½œï¼ŒAIChatåªæ˜¯ä¸€ä¸ªå·¥å…·ï¼Œå®ƒå¯ä»¥å¸®åŠ©æˆ‘ä»¬æ›´é«˜æ•ˆåœ°å®Œæˆå·¥ä½œï¼Œæ— æ³•åšåˆ°å®Œå…¨è‡ªåŠ¨åŒ–ã€‚

## é™„å½•

### å¸¸è§é«˜æ€§èƒ½æ¨¡å‹æ€§èƒ½å¯¹æ¯”

æ‘˜è‡ª[Google Gemini 2.5 Pro](https://blog.google/technology/google-deepmind/gemini-model-thinking-updates-march-2025/)ä¸[Google Gemini 2.5 Flash](https://developers.googleblog.com/en/start-building-with-gemini-25-flash/)çš„å‘å¸ƒé¡µé¢ã€‚ï¼ˆç”±äºæ˜¯Googleå‘å¸ƒçš„ï¼Œå¯èƒ½ç»“æœä¸­ç«‹æ€§å­˜ç–‘ï¼‰

| æŒ‡æ ‡åç§° | Gemini 2.5 Pro | Grok 3 Beta | OpenAI o4-mini | Gemini 2.5 Flash | OpenAI o3-mini | Claude 3.7 Sonnet | DeepSeek R1 | OpenAI GPT-4.5 | Gemini 2.0 Flash |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| Humanity's Last Exam (no tools) | 18.8% | - | 14.3% | 12.1% | 14.0% | 8.9% | 8.6% | 6.4% | 5.1% |
| GPQA diamond (single attempt) | 84.0% | 80.2% | 81.4% | 78.3% | 79.7% | 78.2% | 71.5% | 71.4% | 60.1% |
| GPQA diamond (multiple attempts) | - | 84.6% | - | - | - | 84.8% | - | - | - |
| AIME 2025 (single attempt) | 86.7% | 77.3% | 92.7% | 78.0% | 86.5% | 49.5% | 70.0% | - | 27.5% |
| AIME 2024 (single attempt) | 92.0% | 83.9% | 93.4% | 88.0% | 87.3% | 61.3% | 79.8% | 36.7% | 32.0% |
| AIME 2024 (multiple attempts) | - | 93.3% | - | - | - | 80.0% | - | - | - |
| LiveCodeBench v5 (single attempt) | 70.4% | 70.6% | - | 63.5% | 74.1% | - | 64.3% | - | 34.5% |
| LiveCodeBench v5 (multiple attempts) | - | 79.4% | - | - | - | - | - | - | - |
| Aider Polyglot (whole / diff) | 74.0% / 68.6% | - | 68.9% / 58.2% | 51.1% / 44.2% | 60.4% (diff) | 64.9% (diff) | 56.9% (diff) | 44.9% (diff) | 22.2% (whole) |
| SimpleQA | 52.9% | 43.6% | - | 29.7% | 13.8% | - | 30.1% | 62.5% | 29.9% |
| MMMU (single attempt) | 81.7% | 76.0% | 81.6% | 76.7% | - | 75.0% | - | 74.4% | 71.7% |
| MMMU (multiple attempts) | - | 78.0% | - | - | - | - | - | - | - |
| Vibe-Eval (Reka) | 69.4% | - | - | 62.0% | - | - | - | - | 56.4% |
| MRCR (128k average) | 94.5% | - | - | 84.6% | 61.4% | - | - | 64.0% | 74.2% |
| MRCR (1M pointwise) | 83.1% | - | - | 66.3% | - | - | - | - | 48.2% |
| Global MMLU (Lite) | 89.8% | - | - | 88.4% | - | - | - | - | 83.4% |

### é•¿ä¸Šä¸‹æ–‡æ·±åº¦ç†è§£æ€§èƒ½

ä»¥ä¸‹å†…å®¹æ‘˜è‡ª[Fiction.LiveBench](https://fiction.live/stories/Fiction-liveBench-April-17-2025/oQdzQvKHw8JyXbN87)ã€‚ï¼ˆ2025å¹´4æœˆ17æ—¥å‘å¸ƒï¼‰

| Model | 0 | 400 | 1k | 2k | 4k | 8k | 16k | 32k | 60k | 120k |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| o3 | 100.0 | 100.0 | 100.0 | 100.0 | 100.0 | 100.0 | 88.9 | 100.0 | 83.3 | 100.0 |
| o4-mini | 100.0 | 100.0 | 100.0 | 100.0 | 77.8 | 66.7 | 77.8 | 55.6 | 66.7 | 62.5 |
| o1 | 100.0 | 97.2 | 100.0 | 94.4 | 94.4 | 86.1 | 83.3 | 83.3 | 72.2 | 53.1 |
| o3-mini | 100.0 | 63.9 | 58.3 | 47.2 | 47.2 | 50.0 | 50.0 | 55.6 | 44.4 | 43.8 |
| claude-3-7-sonnet-20250219-thinking | 100.0 | 100.0 | 100.0 | 97.2 | 91.7 | 97.2 | 83.3 | 75.0 | 69.4 | 53.1 |
| deepseek-r1 | 100.0 | 82.2 | 80.6 | 76.7 | 77.8 | 83.3 | 69.4 | 63.9 | 66.7 | 33.3 |
| gemini-2.5-pro-exp-03-25:free | 100.0 | 100.0 | 100.0 | 100.0 | 97.2 | 91.7 | 66.7 | 86.1 | 83.3 | 90.6 |
| gemini-2.5-flash-preview:thinking | 100.0 | 97.2 | 86.1 | 75.0 | 75.0 | 61.1 | 63.9 | 55.6 | 58.3 | 75.0 |
| gemini-2.0-flash-thinking-exp:free | 100.0 | 83.3 | 66.7 | 75.0 | 77.8 | 52.8 | 52.8 | 36.1 | 36.1 | 37.5 |
| qwq-32b:free | 100.0 | 91.7 | 94.4 | 88.9 | 94.4 | 86.1 | 83.3 | 80.6 | 61.1 | - |
| grok-3-mini-beta | 87.5 | 77.8 | 77.8 | 80.6 | 77.8 | 72.2 | 66.7 | 75.0 | 72.2 | 65.6 |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| quasar-alpha | 100.0 | 97.2 | 86.1 | 66.7 | 66.7 | 69.4 | 69.4 | 63.9 | 63.9 | 59.4 |
| optimus-alpha | 100.0 | 91.7 | 77.8 | 72.2 | 61.1 | 55.6 | 61.1 | 55.6 | 58.3 | 59.4 |
| gpt-4.1 | 100.0 | 91.7 | 75.0 | 69.4 | 63.9 | 55.6 | 63.9 | 58.3 | 52.8 | 62.5 |
| gpt-4.1-mini | 75.0 | 66.7 | 55.6 | 41.7 | 44.4 | 41.7 | 44.4 | 38.9 | 38.9 | 46.9 |
| gpt-4.1-nano | 62.5 | 50.0 | 41.7 | 36.1 | 33.3 | 38.9 | 25.0 | 33.3 | 36.1 | 18.8 |
| chatgpt-4o-latest | 87.5 | 83.3 | 66.7 | 63.9 | 63.9 | 66.7 | 66.7 | 63.9 | 55.6 | 65.6 |
| gpt-4.5-preview | 100.0 | 94.4 | 83.3 | 83.3 | 83.3 | 72.2 | 63.9 | 63.9 | 66.7 | 63.9 |
| claude-3-7-sonnet-20250219 | 100.0 | 77.8 | 80.6 | 72.2 | 61.1 | 52.8 | 50.0 | 52.8 | 44.4 | 34.4 |
| claude-3-5-sonnet-20241022 | 100.0 | 77.8 | 69.4 | 55.6 | 50.0 | 38.9 | 38.9 | 36.1 | - | - |
| deepseek-chat-v3-0324:free | 87.5 | 61.1 | 69.4 | 52.8 | 52.8 | 52.8 | 50.0 | 55.6 | 55.6 | - |
| deepseek-chat:free | 87.5 | 61.1 | 61.1 | 55.6 | 55.6 | 50.0 | 61.1 | 16.7 | 19.4 | - |
| qwen-max | 75.0 | 69.4 | 69.4 | 63.9 | 72.2 | 63.9 | 66.7 | - | - | - |
| jamba-1-5-large | 75.0 | 50.0 | 47.2 | 58.3 | 50.0 | 52.8 | 52.8 | 36.1 | 44.4 | 46.9 |
| gemma-3-27b-it:free | 87.5 | 44.4 | 50.0 | 41.7 | 33.3 | 38.9 | 33.3 | 25.0 | 30.6 | - |
| gemini-2.5-flash-preview | 62.5 | 63.9 | 69.4 | 61.1 | 47.2 | 44.4 | 47.2 | 44.4 | 58.3 | 53.1 |
| gemini-2.0-pro-exp-02-05:free | 87.5 | 91.7 | 80.6 | 72.2 | 61.1 | 52.8 | 41.7 | 47.2 | 41.7 | 37.5 |
| gemini-2.0-flash-001 | 100.0 | 63.9 | 58.3 | 55.6 | 47.2 | 50.0 | 61.1 | 50.0 | 47.2 | 62.5 |
| llama-4-maverick:free | 100.0 | 56.0 | 50.0 | 52.0 | 48.0 | 48.0 | 46.2 | 44.0 | 32.0 | 36.4 |
| llama-4-scout:free | 62.5 | 52.0 | 50.0 | 36.0 | 32.0 | 40.0 | 36.0 | 16.0 | 24.0 | 27.3 |
| llama-3.3-70b-instruct | 75.0 | 66.7 | 69.4 | 55.6 | 41.7 | 36.1 | 33.3 | 33.3 | 33.3 | - |
| grok-3-beta | 75.0 | 72.2 | 63.9 | 55.6 | 55.6 | 52.8 | 58.3 | 55.6 | 63.9 | 58.3 |

### æ¨¡å‹å¹»è§‰ç‡æ¦œå•

ä»¥ä¸‹å†…å®¹æ‘˜è‡ª[Hugging Face](https://huggingface.co/spaces/vectara/leaderboard)çš„[æ¦œå•](https://vectara-leaderboard.hf.space/?__theme=system)ï¼Œä½¿ç”¨[Hallucination](https://github.com/vectara/hallucination-leaderboard)è¯„ä¼°ï¼Œåˆ—å‡ºäº†å½“å‰ä¸»æµæ¨¡å‹çš„å¹»è§‰ç‡ã€äº‹å®ä¸€è‡´æ€§ç‡ã€å›ç­”ç‡ç­‰æŒ‡æ ‡ã€‚æˆ‘ä»¬å¯ä»¥æ ¹æ®è¿™äº›æŒ‡æ ‡æ¥é€‰æ‹©åˆé€‚çš„æ¨¡å‹ã€‚[^1]æ‘˜å½•æ—¶é—´ä¸º2025.04.08ã€‚

| T | Model                                             | Hallucination Rate (%) | Factual Consistency Rate (%) | Answer Rate (%) | Average Summary Length | Type            |
|----|---------------------------------------------------|-------------------------|------------------------------|-----------------|-----------------------|-----------------|
| ?  | google/gemini-2.0-flash-001                       | 0.7                     | 99.3                         | 100.0           | 65.2                  |                 |
| ?  | google/gemini-2.0-pro-exp-02-05                   | 0.8                     | 99.2                         | 99.7             | 61.5                  |                 |
| ?  | openai/o3-mini-high-reasoning                     | 0.8                     | 99.2                         | 100.0            | 79.5                  |                 |
| ?  | google/gemini-2.5-pro-exp-03-25                   | 1.1                     | 98.9                         | 95.1             | 72.9                  |                 |
| ?  | google/gemini-2.0-flash-lite-preview-02-05       | 1.2                     | 98.8                         | 99.5             | 60.9                  |                 |
| ?  | openai/gpt-4.5-preview                             | 1.2                     | 98.8                         | 100.0            | 77.0                  |                 |
| ?  | gemini-2.0-flash-exp                               | 1.3                     | 98.7                         | 99.9             | 60.0                  |                 |
| ?  | THUDM/glm-4-9b-chat                                | 1.3                     | 98.7                         | 100.0            | 58.1                  |                 |
| ?  | openai/o1-mini                                     | 1.4                     | 98.6                         | 100.0            | 78.3                  |                 |
| ?  | openai/GPT-4o                                      | 1.5                     | 98.5                         | 100.0            | 77.8                  |                 |
| ?  | amazon/nova-micro-v1                              | 1.6                     | 98.4                         | 100.0            | 90.0                  |                 |
| ğŸŸ¢ | openai/GPT-4-Turbo                                 | 1.7                     | 98.3                         | 100.0            | 86.2                  | pretrained       |
| ?  | openai/GPT-4o-mini                                 | 1.7                     | 98.3                         | 100.0            | 76.3                  |                 |
| ?  | google/gemini-2.0-flash-thinking-exp              | 1.8                     | 98.2                         | 99.3             | 73.2                  |                 |
| ?  | amazon/nova-pro-v1                                 | 1.8                     | 98.2                         | 100.0            | 85.5                  |                 |
| ?  | amazon/nova-lite-v1                                | 1.8                     | 98.2                         | 99.9             | 80.7                  |                 |
| ğŸŸ¢ | openai/GPT-4                                       | 1.8                     | 98.2                         | 100.0            | 81.1                  | pretrained       |
| ?  | x-ai/grok-2-1212                                   | 1.9                     | 98.1                         | 100.0            | 86.5                  |                 |
| ğŸŸ¢ | openai/GPT-3.5-Turbo                               | 1.9                     | 98.1                         | 99.6             | 84.1                  | pretrained       |
| ?  | ai21/jamba-1.6-large                               | 2.3                     | 97.7                         | 99.9             | 85.6                  |                 |
| ?  | deepseek/deepseek-chat                             | 2.4                     | 97.6                         | 100.0            | 83.2                  |                 |
| ?  | openai/o1                                          | 2.4                     | 97.6                         | 99.9             | 73.0                  |                 |
| ?  | openai/o1-pro                                      | 2.4                     | 97.6                         | 100.0            | 81.0                  |                 |
| ?  | microsoft/Orca-2-13b                               | 2.5                     | 97.5                         | 100.0            | 66.2                  |                 |
| ?  | microsoft/Phi-3.5-MoE-instruct                     | 2.5                     | 97.5                         | 96.3             | 69.7                  |                 |
| ğŸŸ¦ | Intel/neural-chat-7b-v3-3                          | 2.6                     | 97.4                         | 100.0            | 60.7                  | RL-tuned         |
| ?  | Qwen/Qwen2.5-7B-Instruct                           | 2.8                     | 97.2                         | 100.0            | 71.0                  |                 |
| ?  | google/gemma-3-12b-it                              | 2.8                     | 97.2                         | 100.0            | 69.6                  |                 |
| ?  | x-ai/grok-2-vision-1212                            | 2.9                     | 97.1                         | 100.0            | 79.8                  |                 |
| ?  | ai21labs/AI21-Jamba-1.5-Mini                      | 2.9                     | 97.1                         | 95.6             | 74.5                  |                 |
| ?  | qwen/qwen-max                                      | 2.9                     | 97.1                         | 88.4             | 90.4                  |                 |
| ?  | Qwen/Qwen2.5-32B-Instruct                          | 3.0                     | 97.0                         | 100.0            | 67.9                  |                 |
| ?  | snowflake/snowflake-arctic-instruct                | 3.0                     | 97.0                         | 100.0            | 68.7                  |                 |
| ?  | google/gemma-3-27b-it                              | 3.0                     | 97.0                         | 100.0            | 62.5                  |                 |
| ?  | microsoft/Phi-3-mini-128k-instruct                 | 3.1                     | 96.9                         | 100.0            | 60.1                  |                 |
| ?  | mistralai/Mistral-Small-24B-Instruct-2501         | 3.1                     | 96.9                         | 100.0            | 74.9                  |                 |
| ?  | openai/o1-preview                                  | 3.3                     | 96.7                         | 100.0            | 119.3                 |                 |
| ?  | google/gemini-1.5-flash-002                       | 3.4                     | 96.6                         | 99.9             | 59.4                  |                 |
| ?  | microsoft/Phi-4-mini-instruct                      | 3.4                     | 96.6                         | 100.0            | 69.7                  |                 |
| ?  | openai/chatgpt-4o-latest                           | 3.5                     | 96.5                         | 100.0            | 63.5                  |                 |
| ?  | 01-ai/Yi-1.5-34B-Chat                             | 3.7                     | 96.3                         | 100.0            | 83.7                  |                 |
| ?  | google/gemma-3-4b-it                               | 3.7                     | 96.3                         | 100.0            | 63.7                  |                 |
| ?  | meta-llama/Meta-Llama-3.1-405B-Instruct            | 3.9                     | 96.1                         | 99.6             | 85.7                  |                 |
| ?  | deepseek/deepseek-v3                               | 3.9                     | 96.1                         | 100.0            | 88.2                  |                 |
| ?  | meta-llama/Llama-3.3-70B-Instruct                  | 4.0                     | 96.0                         | 100.0            | 85.3                  |                 |
| ?  | microsoft/Phi-3-mini-4k-instruct                   | 4.0                     | 96.0                         | 100.0            | 86.8                  |                 |
| ?  | internlm/internlm3-8b-instruct                     | 4.0                     | 96.0                         | 100.0            | 97.5                  |                 |
| ?  | mistralai/Mistral-Large2                           | 4.1                     | 95.9                         | 100.0            | 77.4                  |                 |
| ?  | meta-llama/Llama-3-70B-chat-hf                     | 4.1                     | 95.9                         | 99.2             | 68.5                  |                 |
| ?  | microsoft/Phi-3.5-mini-instruct                    | 4.1                     | 95.9                         | 100.0            | 75.0                  |                 |
| ?  | Qwen/Qwen2.5-14B-Instruct                          | 4.2                     | 95.8                         | 100.0            | 74.8                  |                 |
| ?  | Qwen/Qwen2-VL-7B-Instruct                          | 4.2                     | 95.8                         | 100.0            | 73.9                  |                 |
| ?  | Qwen/Qwen2.5-72B-Instruct                          | 4.3                     | 95.7                         | 100.0            | 80.8                  |                 |
| ?  | meta-llama/Llama-3.2-90B-Vision-Instruct-Turbo    | 4.3                     | 95.7                         | 100.0            | 79.8                  |                 |
| ?  | anthropic/claude-3-7-sonnet-latest                 | 4.4                     | 95.6                         | 100.0            | 97.8                  |                 |
| ?  | anthropic/claude-3-7-sonnet-latest-think           | 4.5                     | 95.5                         | 99.8             | 99.9                  |                 |
| ?  | cohere/command-a-03-2025                           | 4.5                     | 95.5                         | 100.0            | 77.3                  |                 |
| ?  | meta-llama/llama-4-maverick                        | 4.6                     | 95.4                         | 100.0            | 84.8                  |                 |
| ?  | xai/grok-beta                                      | 4.6                     | 95.4                         | 100.0            | 91.0                  |                 |
| ?  | ai21/jamba-1.6-mini                                | 4.6                     | 95.4                         | 100.0            | 82.3                  |                 |
| ?  | anthropic/Claude-3-5-sonnet                        | 4.6                     | 95.4                         | 100.0            | 95.9                  |                 |
| ?  | Qwen/Qwen2-72B-Instruct                            | 4.7                     | 95.3                         | 100.0            | 100.1                 |                 |
| ?  | mistralai/Mixtral-8x22B-Instruct-v0.1              | 4.7                     | 95.3                         | 99.9             | 92.0                  |                 |
| ?  | microsoft/phi-4                                    | 4.7                     | 95.3                         | 100.0            | 100.3                 |                 |
| ?  | meta-llama/llama-4-scout                           | 4.7                     | 95.3                         | 100.0            | 80.7                  |                 |
| ?  | anthropic/claude-3-5-haiku-20241022                | 4.9                     | 95.1                         | 100.0            | 92.2                  |                 |
| ?  | 01-ai/Yi-1.5-9B-Chat                              | 4.9                     | 95.1                         | 100.0            | 85.7                  |                 |
| ?  | allenai/olmo-2-0325-32b-instruct                  | 4.9                     | 95.1                         | 99.9             | 100.0                 |                 |
| ?  | cohere/command-r-08-2024                           | 4.9                     | 95.1                         | 100.0            | 68.7                  |                 |
| ?  | meta-llama/Meta-Llama-3.1-70B-Instruct             | 5.0                     | 95.0                         | 100.0            | 79.6                  |                 |
| ?  | google/gemma-3-1b-it                               | 5.3                     | 94.7                         | 99.9             | 57.9                  |                 |
| ?  | cohere/command-r-plus-08-2024                      | 5.4                     | 94.6                         | 100.0            | 68.4                  |                 |
| ?  | meta-llama/Meta-Llama-3.1-8B-Instruct              | 5.4                     | 94.6                         | 100.0            | 71.0                  |                 |
| ?  | meta-llama/Llama-3.2-11B-Vision-Instruct-Turbo    | 5.5                     | 94.5                         | 100.0            | 67.3                  |                 |
| ?  | mistralai/mistral-small-3.1-24b-instruct           | 5.6                     | 94.4                         | 100.0            | 73.1                  |                 |
| ?  | mistralai/mistral-large-latest                     | 5.864811133200803      | 94.1351888667992             | 100.0            | 79.55367793240556     |                 |
| ğŸŸ¢ | meta-llama/Llama-2-70b-chat-hf                     | 5.9                     | 94.1                         | 99.9             | 84.9                  | pretrained       |
| ?  | ibm-granite/granite-3.0-8b-instruct                | 6.5                     | 93.5                         | 100.0            | 74.2                  |                 |
| ?  | google/gemini-1.5-pro-002                          | 6.6                     | 93.4                         | 99.9             | 62.0                  |                 |
| ?  | google/gemini-1.5-flash-001                       | 6.6                     | 93.4                         | 99.9             | 63.3                  |                 |
| ?  | mistralai/pixtral-large-latest                     | 6.6                     | 93.4                         | 100.0            | 76.4                  |                 |
| ğŸŸ¢ | microsoft/phi-2                                    | 6.7                     | 93.3                         | 91.5             | 80.8                  | pretrained       |
| ?  | Qwen/Qwen2.5-3B-Instruct                           | 7.0                     | 93.0                         | 100.0            | 70.4                  |                 |
| ?  | google/gemma-2-2b-it                               | 7.0                     | 93.0                         | 100.0            | 62.2                  |                 |
| ?  | meta-llama/Llama-3-8B-chat-hf                     | 7.4                     | 92.6                         | 99.8             | 79.7                  |                 |
| ?  | mistralai/ministral-8b-latest                      | 7.5                     | 92.5                         | 100.0            | 62.7                  |                 |
| ğŸŸ¢ | google/Gemini-Pro                                  | 7.7                     | 92.3                         | 98.4             | 89.5                  | pretrained       |
| ?  | 01-ai/Yi-1.5-6B-Chat                               | 7.9                     | 92.1                         | 100.0            | 98.9                  |                 |
| ?  | meta-llama/Llama-3.2-3B-Instruct-Turbo            | 7.9                     | 92.1                         | 100.0            | 72.2                  |                 |
| ?  | deepseek/deepseek-v3-0324                          | 8.0                     | 92.0                         | 100.0            | 78.9                  |                 |
| ?  | databricks/dbrx-instruct                           | 8.3                     | 91.7                         | 100.0            | 85.9                  |                 |
| ?  | mistralai/ministral-3b-latest                      | 8.3                     | 91.7                         | 100.0            | 73.2                  |                 |
| ?  | Qwen/Qwen2-VL-2B-Instruct                          | 8.3                     | 91.7                         | 100.0            | 81.8                  |                 |
| ?  | cohere/c4ai-aya-expanse-32b                       | 8.5                     | 91.5                         | 99.9             | 81.9                  |                 |
| ?  | anthropic/Claude-3-5-Sonnet                        | 8.6                     | 91.4                         | 100.0            | 103.0                 |                 |
| ?  | mistralai/mistral-small-latest                     | 8.6                     | 91.4                         | 100.0            | 74.2                  |                 |
| ?  | ibm-granite/granite-3.1-8b-instruct                | 8.6                     | 91.4                         | 100.0            | 107.4                 |                 |
| ?  | ibm-granite/granite-3.2-8b-instruct                | 8.7                     | 91.3                         | 100.0            | 120.1                 |                 |
| ?  | ibm-granite/granite-3.0-2b-instruct                | 8.8                     | 91.2                         | 100.0            | 81.6                  |                 |
| ?  | google/gemini-1.5-pro-001                          | 9.1                     | 90.9                         | 99.8             | 61.6                  |                 |
| ?  | mistralai/Mistral-7B-Instruct-v0.3                 | 9.5                     | 90.5                         | 100.0            | 98.4                  |                 |
| ğŸŸ¢ | anthropic/Claude-3-opus                            | 10.1                    | 89.9                         | 95.5             | 92.1                  | pretrained       |
| ?  | google/gemma-2-9b-it                               | 10.1                    | 89.9                         | 100.0            | 70.2                  |                 |
| ğŸŸ¢ | meta-llama/Llama-2-13b-chat-hf                     | 10.5                    | 89.5                         | 99.8             | 82.1                  | pretrained       |
| ?  | allenai/OLMo-2-1124-13B-Instruct                   | 10.8                    | 89.2                         | 100.0            | 82.0                  |                 |
| ?  | allenai/OLMo-2-1124-7B-Instruct                   | 11.1                    | 88.9                         | 100.0            | 112.6                 |                 |
| ?  | mistralai/Mistral-Nemo-Instruct-2407               | 11.2                    | 88.8                         | 100.0            | 69.9                  |                 |
| ğŸŸ¢ | meta-llama/Llama-2-7b-chat-hf                     | 11.3                    | 88.7                         | 99.6             | 119.9                 | pretrained       |
| ?  | microsoft/WizardLM-2-8x22B                        | 11.7                    | 88.3                         | 99.9             | 140.8                 |                 |
| ?  | cohere/c4ai-aya-expanse-8b                        | 12.2                    | 87.8                         | 99.9             | 83.9                  |                 |
| ?  | Qwen/QwQ-32B-Preview                               | 12.9                    | 87.1                         | 100.0            | 140.2                 |                 |
| ğŸŸ¢ | amazon/Titan-Express                               | 13.5                    | 86.5                         | 99.5             | 98.4                  | pretrained       |
| ğŸŸ¢ | google/PaLM-2                                      | 14.1                    | 85.9                         | 99.8             | 86.6                  | pretrained       |
| ?  | deepseek/deepseek-r1                               | 14.3                    | 85.7                         | 100.0            | 77.1                  |                 |
| â­• | google/gemma-7b-it                                 | 14.8                    | 85.2                         | 100.0            | 113.0                 | instruction-tuned |
| ?  | ibm-granite/granite-3.1-2b-instruct                | 15.7                    | 84.3                         | 100.0            | 107.7                 |                 |
| ?  | Qwen/Qwen2.5-1.5B-Instruct                         | 15.8                    | 84.2                         | 100.0            | 70.7                  |                 |
| ğŸŸ¢ | anthropic/Claude-3-sonnet                          | 16.3                    | 83.7                         | 100.0            | 108.5                 | pretrained       |
| ?  | ibm-granite/granite-3.2-2b-instruct                | 16.5                    | 83.5                         | 100.0            | 117.3                 |                 |
| ?  | google/gemma-1.1-7b-it                             | 17.0                    | 83.0                         | 100.0            | 64.3                  |                 |
| ğŸŸ¢ | anthropic/Claude-2                                 | 17.4                    | 82.6                         | 99.3             | 87.5                  | pretrained       |
| ?  | google/flan-t5-large                               | 18.3                    | 81.7                         | 99.3             | 20.9                  |                 |
| â­• | mistralai/Mixtral-8x7B-Instruct-v0.1               | 20.1                    | 79.9                         | 99.9             | 90.7                  | instruction-tuned |
| ?  | meta-llama/Llama-3.2-1B-Instruct                   | 20.7                    | 79.3                         | 100.0            | 71.5                  |                 |
| ?  | apple/OpenELM-3B-Instruct                          | 24.8                    | 75.2                         | 99.3             | 47.2                  |                 |
| ?  | Qwen/Qwen2.5-0.5B-Instruct                         | 25.2                    | 74.8                         | 100.0            | 72.6                  |                 |
| ?  | google/gemma-1.1-2b-it                             | 27.8                    | 72.2                         | 100.0            | 66.8                  |                 |
| â­• | tiiuae/falcon-7b-instruct                          | 29.9                    | 70.1                         | 90.0             | 75.5                  | instruction-tuned |

[^1]: **S. Hughes, M. Bae**, "Vectara Hallucination Leaderboard", Vectara, Inc., 2023. [Online]. Available: [https://github.com/vectara/hallucination-leaderboard](https://github.com/vectara/hallucination-leaderboard).

### æ¨¡å‹æ™ºèƒ½æ¦œå•

ä»¥ä¸‹æ˜¯å¯¹æ¨¡å‹çš„æ™ºèƒ½æ–¹é¢çš„è¯„ä¼°ï¼Œé€‰æ‹©æ€§æ‘˜å½•è‡ª[Artificial Analysis](https://artificialanalysis.ai/leaderboards/models)ã€‚æ‘˜å½•æ—¶é—´ä¸º2025.04.13ã€‚

| æ¨¡å‹åç§°                          | Context Window | Artificial Analysis Intelligence Index | MMLU-Pro (Reasoning & Knowledge) | GPQA Diamond (Scientific Reasoning) | Humanity's Last Exam (Reasoning & Knowledge) | LiveCodeBench (Coding) | SciCode (Coding) | HumanEval (Coding) | Math-500 (Quantitative Reasoning) | AIME 2024 (Competition Math) | Multilingual Index (Artificial Analysis) | Chatbot Arena |
|-----------------------------------|----------------|----------------------------------------|----------------------------------|-------------------------------------|-----------------------------------------------|------------------------|------------------|--------------------|-----------------------------------|-----------------------------|------------------------------------------|---------------|
| Gemini 2.5 Pro Experimental       | 1m             | 68                                     | 86%                              | 84%                                 | 17%                                           | 70%                    | 39%              | 99%                | 98%                              | 87%                        | -                                        | -             |
| o3-mini (high)                    | 200k           | 66                                     | 80%                              | 77%                                 | 12%                                           | 73%                    | 40%              | -                  | 99%                              | 86%                        | -                                        | -             |
| o3-mini                           | 200k           | 63                                     | 79%                              | 75%                                 | 9%                                            | 72%                    | 40%              | 97%                | 97%                              | 77%                        | -                                        | -             |
| o1                                | 200k           | 62                                     | 84%                              | 75%                                 | 8%                                            | 68%                    | 36%              | 97%                | 97%                              | 72%                        | 88%                                      | -             |
| DeepSeek R1                       | 128k           | 60                                     | 84%                              | 71%                                 | 9%                                            | 62%                    | 36%              | 98%                | 97%                              | 68%                        | -                                        | -             |
| QwQ-32B                           | 131k           | 58                                     | 76%                              | 59%                                 | 8%                                            | 63%                    | 36%              | 98%                | 96%                              | 78%                        | -                                        | -             |
| Claude 3.7 Sonnet Thinking        | 200k           | 57                                     | 84%                              | 77%                                 | 10%                                           | 47%                    | 40%              | 98%                | 95%                              | 49%                        | -                                        | -             |
| o1-mini                           | 128k           | 54                                     | 74%                              | 60%                                 | 5%                                            | 58%                    | 32%              | 97%                | 94%                              | 60%                        | 83%                                      | 1308          |
| DeepSeek V3 (Mar' 25)             | 128k           | 53                                     | 82%                              | 66%                                 | 5%                                            | 41%                    | 36%              | 92%                | 94%                              | 52%                        | -                                        | -             |
| Gemini 2.0 Flash Thinking exp. (Jan '25) | 1m             | 52                                     | 80%                              | 70%                                 | 7%                                            | 32%                    | 33%              | -                  | 94%                              | 50%                        | -                                        | -             |
| DeepSeek R1 Distill Qwen 32B      | 128k           | 52                                     | 74%                              | 62%                                 | 6%                                            | 27%                    | 38%              | 95%                | 94%                              | 69%                        | -                                        | -             |
| Llama 4 Maverick                  | 1m             | 51                                     | 81%                              | 67%                                 | 5%                                            | 40%                    | 33%              | 88%                | 89%                              | 39%                        | -                                        | -             |
| GPT-4o (March 2025)               | 128k           | 50                                     | 80%                              | 66%                                 | 5%                                            | 43%                    | 37%              | 96%                | 89%                              | 33%                        | -                                        | -             |
| Grok 3                            | 1m             | 50                                     | 80%                              | 67%                                 | 5%                                            | 42%                    | 37%              | 91%                | 87%                              | 30%                        | -                                        | -             |
| Gemini 2.0 Pro Experimental       | 2m             | 49                                     | 81%                              | 62%                                 | 7%                                            | 35%                    | 31%              | 95%                | 92%                              | 36%                        | -                                        | -             |
| DeepSeek R1 Distill Qwen 14B      | 128k           | 49                                     | 74%                              | 48%                                 | 4%                                            | 38%                    | 24%              | 93%                | 95%                              | 67%                        | -                                        | -             |
| DeepSeek R1 Distill Llama 70B     | 128k           | 48                                     | 80%                              | 40%                                 | 6%                                            | 27%                    | 31%              | 97%                | 94%                              | 67%                        | -                                        | -             |
| Claude 3.7 Sonnet                 | 200k           | 48                                     | 80%                              | 66%                                 | 5%                                            | 39%                    | 38%              | 95%                | 85%                              | 22%                        | -                                        | -             |
| Gemini 2.0 Flash                  | 1m             | 48                                     | 78%                              | 62%                                 | 5%                                            | 33%                    | 31%              | 90%                | 93%                              | 33%                        | -                                        | -             |
| Reka Flash 3                      | 128k           | 47                                     | 67%                              | 53%                                 | 5%                                            | 44%                    | 27%              | 95%                | 89%                              | 51%                        | -                                        | -             |
| Gemini 2.0 Flash (exp)            | 1m             | 46                                     | 78%                              | 64%                                 | 5%                                            | 21%                    | 34%              | 91%                | 91%                              | 30%                        | 84%                                      | -             |
| DeepSeek V3 (Dec '24)             | 128k           | 46                                     | 75%                              | 56%                                 | 4%                                            | 36%                    | 35%              | 91%                | 89%                              | 25%                        | 86%                                      | -             |
| Qwen2.5 Max                       | 32k             | 45                                     | 76%                              | 59%                                 | 5%                                            | 36%                    | 34%              | 93%                | 84%                              | 23%                        | -                                        | -             |
| Gemini 1.5 Pro (Sep)              | 2m             | 45                                     | 75%                              | 59%                                 | 5%                                            | 32%                    | 30%              | 90%                | 88%                              | 23%                        | 85%                                      | 1301          |
| Claude 3.5 Sonnet (Oct)           | 200k           | 44                                     | 77%                              | 60%                                 | 4%                                            | 38%                    | 37%              | 93%                | 77%                              | 16%                        | 88%                                      | 1282          |
| Sonar                             | 127k           | 43                                     | 69%                              | 47%                                 | 7%                                            | 30%                    | 23%              | 82%                | 82%                              | 49%                        | -                                        | -             |
| Llama 4 Scout                     | 10m            | 43                                     | 75%                              | 59%                                 | 4%                                            | 30%                    | 17%              | 83%                | 84%                              | 28%                        | -                                        | -             |
| Sonar Pro                         | 200k           | 43                                     | 76%                              | 58%                                 | 8%                                            | 28%                    | 23%              | 85%                | 75%                              | 29%                        | -                                        | -             |
| QwQ 32B-Preview                   | 33k             | 43                                     | 65%                              | 56%                                 | 5%                                            | 34%                    | 4%               | 87%                | 91%                              | 45%                        | -                                        | -             |
| GPT-4o (Nov '24)                  | 128k           | 41                                     | 75%                              | 54%                                 | 3%                                            | 31%                    | 33%              | 93%                | 76%                              | 15%                        | 84%                                      | 1361          |
| Gemini 2.0 Flash-Lite (Feb '25)   | 1m             | 41                                     | 72%                              | 54%                                 | 4%                                            | 19%                    | 25%              | 88%                | 87%                              | 28%                        | -                                        | -             |
| Llama 3.3 70B                     | 128k           | 41                                     | 71%                              | 50%                                 | 4%                                            | 29%                    | 26%              | 86%                | 77%                              | 30%                        | 84%                                      | -             |
| GPT-4o (May '24)                  | 128k           | 41                                     | 74%                              | 53%                                 | 3%                                            | 33%                    | 31%              | 94%                | 79%                              | 11%                        | -                                        | 1285          |
| Llama 3.1 405B                    | 128k           | 40                                     | 73%                              | 52%                                 | 4%                                            | 31%                    | 30%              | 85%                | 70%                              | 21%                        | 77%                                      | 1266          |
| Qwen2.5 72B                       | 131k           | 40                                     | 72%                              | 49%                                 | 4%                                            | 28%                    | 27%              | 88%                | 86%                              | 16%                        | 83%                                      | 1259          |
| MiniMax-Text-01                   | 4m             | 40                                     | 76%                              | 58%                                 | 4%                                            | 25%                    | 25%              | 86%                | 75%                              | 13%                        | -                                        | -             |
| Phi-4                             | 16k             | 40                                     | 71%                              | 57%                                 | 4%                                            | 23%                    | 26%              | 87%                | 81%                              | 14%                        | -                                        | -             |
| Command A                         | 256k           | 40                                     | 71%                              | 53%                                 | 5%                                            | 29%                    | 28%              | 82%                | 82%                              | 10%                        | -                                        | -             |
| Tulu3 405B                        | 128k           | 40                                     | 72%                              | 52%                                 | 4%                                            | 29%                    | 30%              | 89%                | 78%                              | 13%                        | -                                        | -             |
| Llama 3.3 Nemotron Super 49B v1   | 128k           | 39                                     | 70%                              | 52%                                 | 4%                                            | 28%                    | 23%              | 83%                | 78%                              | 19%                        | -                                        | -             |
| Grok 2                            | 131k           | 39                                     | 71%                              | 51%                                 | 4%                                            | 27%                    | 28%              | 86%                | 78%                              | 13%                        | -                                        | -             |
| Gemini 1.5 Flash (Sep)            | 1m             | 39                                     | 68%                              | 46%                                 | 4%                                            | 27%                    | 27%              | 84%                | 83%                              | 18%                        | 81%                                      | 1271          |
| Mistral Large 2 (Nov '24)         | 128k           | 38                                     | 70%                              | 49%                                 | 4%                                            | 29%                    | 29%              | 90%                | 74%                              | 11%                        | 83%                                      | -             |
| Gemma 3 27B                       | 128k           | 38                                     | 67%                              | 43%                                 | 5%                                            | 14%                    | 21%              | 89%                | 88%                              | 25%                        | -                                        | -             |
| Grok Beta                         | 128k           | 38                                     | 70%                              | 47%                                 | 5%                                            | 24%                    | 30%              | 87%                | 74%                              | 10%                        | -                                        | 1289          |
| Pixtral Large                     | 128k           | 37                                     | 70%                              | 51%                                 | 4%                                            | 26%                    | 29%              | 85%                | 71%                              | 7%                         | -                                        | -             |
| Qwen2.5 Instruct 32B              | 128k           | 37                                     | 70%                              | 47%                                 | 4%                                            | 25%                    | 23%              | 90%                | 81%                              | 11%                        | -                                        | -             |
| Llama 3.1 Nemotron 70B            | 128k           | 37                                     | 69%                              | 47%                                 | 5%                                            | 17%                    | 23%              | 82%                | 73%                              | 25%                        | -                                        | 1269          |
| Nova Pro                          | 300k           | 37                                     | 69%                              | 50%                                 | 3%                                            | 23%                    | 21%              | 83%                | 79%                              | 11%                        | 83%                                      | -             |
| Mistral Large 2 (Jul '24)         | 128k           | 37                                     | 68%                              | 47%                                 | 3%                                            | 27%                    | 27%              | 89%                | 71%                              | 9%                         | -                                        | 1251          |
| Qwen2.5 Coder 32B                 | 131k           | 36                                     | 64%                              | 42%                                 | 4%                                            | 30%                    | 27%              | 90%                | 77%                              | 12%                        | -                                        | 1220          |
| GPT-4o mini                       | 128k           | 36                                     | 65%                              | 43%                                 | 4%                                            | 23%                    | 23%              | 88%                | 79%                              | 12%                        | 80%                                      | 1273          |
| Llama 3.1 70B                     | 128k           | 35                                     | 68%                              | 41%                                 | 5%                                            | 23%                    | 27%              | 81%                | 65%                              | 17%                        | -                                        | 1249          |
| Mistral Small 3.1                 | 128k           | 35                                     | 66%                              | 45%                                 | 5%                                            | 21%                    | 27%              | 86%                | 71%                              | 9%                         | -                                        | -             |
| Mistral Small 3                   | 32k             | 35                                     | 65%                              | 46%                                 | 4%                                            | 25%                    | 24%              | 85%                | 72%                              | 8%                         | -                                        | -             |
| Claude 3 Opus                     | 200k           | 35                                     | 70%                              | 49%                                 | 3%                                            | 28%                    | 23%              | 85%                | 64%                              | 3%                         | -                                        | 1248          |
| Claude 3.5 Haiku                  | 200k           | 35                                     | 63%                              | 41%                                 | 4%                                            | 31%                    | 27%              | 86%                | 72%                              | 3%                         | 78%                                      | -             |
| DeepSeek R1 Distill Llama 8B      | 128k           | 34                                     | 54%                              | 30%                                 | 4%                                            | 23%                    | 12%              | 84%                | 85%                              | 33%                        | -                                        | -             |
| Gemma 3 12B                       | 128k           | 34                                     | 60%                              | 35%                                 | 5%                                            | 14%                    | 17%              | 83%                | 85%                              | 22%                        | -                                        | -             |
| Gemini 1.5 Pro (May)              | 2m             | 34                                     | 66%                              | 37%                                 | 4%                                            | 24%                    | 27%              | 83%                | 67%                              | 8%                         | -                                        | 1260          |
| Qwen Turbo                        | 1m             | 34                                     | 63%                              | 41%                                 | 4%                                            | 16%                    | 15%              | 85%                | 81%                              | 12%                        | -                                        | -             |
| Llama 3.2 90B (Vision)            | 128k           | 33                                     | 67%                              | 43%                                 | 5%                                            | 21%                    | 24%              | 82%                | 63%                              | 5%                         | -                                        | -             |
| Qwen2 72B                         | 131k           | 33                                     | 62%                              | 37%                                 | 4%                                            | 16%                    | 23%              | 83%                | 70%                              | 15%                        | -                                        | 1187          |
| Nova Lite                         | 300k           | 33                                     | 59%                              | 43%                                 | 5%                                            | 17%                    | 14%              | 84%                | 77%                              | 11%                        | 76%                                      | -             |
| Gemini 1.5 Flash-8B               | 1m             | 31                                     | 57%                              | 36%                                 | 5%                                            | 22%                    | 23%              | 12%                | 69%                              | 3%                         | 74%                                      | 1211          |
| Jamba 1.5 Large                   | 256k           | 29                                     | 57%                              | 43%                                 | 4%                                            | 14%                    | 16%              | 24%                | 61%                              | 5%                         | -                                        | 1221          |
| Jamba 1.6 Large                   | 256k           | 29                                     | 56%                              | 39%                                 | 4%                                            | 17%                    | 18%              | 70%                | 58%                              | 5%                         | -                                        | -             |
| Gemini 1.5 Flash (May)            | 1m             | 28                                     | 57%                              | 32%                                 | 4%                                            | 20%                    | 18%              | 72%                | 55%                              | 9%                         | -                                        | 1227          |
| Nova Micro                        | 130k           | 28                                     | 53%                              | 36%                                 | 5%                                            | 14%                    | 9%               | 80%                | 70%                              | 8%                         | 71%                                      | -             |
| Yi-Large                          | 32k             | 28                                     | 59%                              | 36%                                 | 3%                                            | 11%                    | 19%              | 74%                | 56%                              | 7%                         | -                                        | 1213          |
| Claude 3 Sonnet                   | 200k           | 28                                     | 58%                              | 40%                                 | 4%                                            | 18%                    | 23%              | 71%                | 41%                              | 5%                         | -                                        | 1201          |
| Codestral (Jan '25)               | 256k           | 28                                     | 45%                              | 31%                                 | 5%                                            | 24%                    | 25%              | 85%                | 61%                              | 4%                         | -                                        | -             |
| Llama 3 70B                       | 8k              | 27                                     | 57%                              | 38%                                 | 4%                                            | 20%                    | 19%              | 79%                | 48%                              | 0%                         | -                                        | 1206          |
| Mistral Small (Sep '24)           | 33k             | 27                                     | 53%                              | 38%                                 | 4%                                            | 14%                    | 16%              | 81%                | 56%                              | 6%                         | -                                        | -             |
| Phi-4 Multimodal                  | 128k           | 27                                     | 49%                              | 32%                                 | 4%                                            | 13%                    | 11%              | 73%                | 69%                              | 9%                         | -                                        | -             |
| Qwen2.5 Coder 7B                  | 131k           | 27                                     | 47%                              | 34%                                 | 5%                                            | 13%                    | 15%              | 90%                | 66%                              | 5%                         | -                                        | -             |
| Mistral Large (Feb '24)           | 33k             | 26                                     | 52%                              | 35%                                 | 3%                                            | 18%                    | 21%              | 71%                | 53%                              | 0%                         | -                                        | 1157          |
| Mixtral 8x22B                     | 65k             | 26                                     | 54%                              | 33%                                 | 4%                                            | 15%                    | 19%              | 72%                | 55%                              | 0%                         | -                                        | 1148          |
| Phi-4 Mini                        | 128k           | 26                                     | 47%                              | 33%                                 | 4%                                            | 13%                    | 11%              | 74%                | 70%                              | 3%                         | -                                        | -             |
| Phi-3 Medium 14B                  | 128k           | 25                                     | 54%                              | 33%                                 | 5%                                            | 15%                    | 12%              | 0%                 | 46%                              | 1%                         | -                                        | 1123          |
| Gemma 3 4B                        | 128k           | 24                                     | 42%                              | 29%                                 | 5%                                            | 7%                     | 6%               | 72%                | 77%                              | 5%                         | -                                        | -             |
| Claude 2.1                        | 200k           | 24                                     | 50%                              | 32%                                 | 4%                                            | 20%                    | 18%              | 16%                | 37%                              | 3%                         | -                                        | 1118          |
| Llama 3.1 8B                      | 128k           | 24                                     | 48%                              | 26%                                 | 5%                                            | 12%                    | 13%              | 67%                | 52%                              | 8%                         | 61%                                      | 1172          |
| Pixtral 12B                       | 128k           | 23                                     | 47%                              | 34%                                 | 5%                                            | 12%                    | 14%              | 78%                | 46%                              | 0%                         | -                                        | -             |
| Mistral Small (Feb '24)           | 33k             | 23                                     | 42%                              | 30%                                 | 4%                                            | 11%                    | 13%              | 79%                | 56%                              | 1%                         | -                                        | -             |
| Mistral Medium                    | 33k             | 23                                     | 49%                              | 35%                                 | 3%                                            | 10%                    | 12%              | -                  | 41%                              | 4%                         | -                                        | 1148          |
| Ministral 8B                      | 128k           | 22                                     | 39%                              | 28%                                 | 5%                                            | 11%                    | 12%              | 77%                | 57%                              | 4%                         | -                                        | 1183          |
| Gemma 2 9B                        | 8k              | 22                                     | 50%                              | 31%                                 | 4%                                            | 13%                    | 1%               | 65%                | 52%                              | 0%                         | -                                        | 1190          |
| Phi-3 Mini                        | 4k              | 22                                     | 44%                              | 32%                                 | 4%                                            | 12%                    | 9%               | 25%                | 46%                              | 4%                         | -                                        | 1037          |
| LFM 40B                           | 32k             | 22                                     | 43%                              | 33%                                 | 5%                                            | 10%                    | 7%               | 51%                | 48%                              | 2%                         | -                                        | -             |
| Command-R+                        | 128k           | 21                                     | 43%                              | 34%                                 | 5%                                            | 11%                    | 12%              | 63%                | 40%                              | 0%                         | -                                        | 1215          |
| Llama 3 8B                        | 8k              | 21                                     | 41%                              | 30%                                 | 5%                                            | 10%                    | 12%              | 71%                | 50%                              | 0%                         | -                                        | 1152          |
| Gemini 1.0 Pro                    | 33k             | 21                                     | 43%                              | 28%                                 | 5%                                            | 12%                    | 12%              | 2%                 | 40%                              | 1%                         | -                                        | 1111          |
| Codestral (May '24)               | 33k             | 20                                     | 33%                              | 26%                                 | 5%                                            | 21%                    | 22%              | 80%                | 35%                              | 0%                         | -                                        | -             |
| Aya Expanse 32B                   | 128k           | 20                                     | 38%                              | 23%                                 | 5%                                            | 14%                    | 15%              | 68%                | 45%                              | 0%                         | 65%                                      | 1207          |
| Llama 2 Chat 13B                  | 4k              | 20                                     | 41%                              | 32%                                 | 5%                                            | 10%                    | 12%              | -                  | 33%                              | 2%                         | -                                        | 1063          |
| Command-R+ (Apr '24)              | 128k           | 20                                     | 43%                              | 32%                                 | 5%                                            | 12%                    | 12%              | 64%                | 28%                              | 1%                         | -                                        | 1190          |
| DBRX                              | 33k             | 20                                     | 40%                              | 33%                                 | 7%                                            | 9%                     | 12%              | 67%                | 28%                              | 3%                         | -                                        | 1103          |
| Ministral 3B                      | 128k           | 20                                     | 34%                              | 26%                                 | 6%                                            | 7%                     | 9%               | 74%                | 54%                              | 0%                         | -                                        | -             |
| Mistral NeMo                      | 128k           | 20                                     | 40%                              | 31%                                 | 4%                                            | 6%                     | 10%              | 65%                | 40%                              | 0%                         | -                                        | -             |
| Llama 3.2 3B                      | 128k           | 20                                     | 35%                              | 26%                                 | 5%                                            | 8%                     | 5%               | 56%                | 49%                              | 7%                         | -                                        | 1103          |
| DeepSeek R1 Distill Qwen 1.5B     | 128k           | 19                                     | 27%                              | 10%                                 | 3%                                            | 7%                     | 7%               | 45%                | 69%                              | 18%                        | -                                        | -             |
| Jamba 1.5 Mini                    | 256k           | 18                                     | 37%                              | 30%                                 | 5%                                            | 6%                     | 8%               | 63%                | 36%                              | 1%                         | -                                        | 1176          |
| Jamba 1.6 Mini                    | 256k           | 18                                     | 37%                              | 30%                                 | 5%                                            | 7%                     | 10%              | 43%                | 26%                              | 3%                         | -                                        | -             |
| Mixtral 8x7B                      | 33k             | 17                                     | 39%                              | 29%                                 | 5%                                            | 7%                     | 3%               | 1%                 | 30%                              | 0%                         | -                                        | 1114          |
| Aya Expanse 8B                    | 8k              | 16                                     | 31%                              | 25%                                 | 5%                                            | 7%                     | 8%               | 44%                | 32%                              | 0%                         | 49%                                      | -             |
| Command-R                         | 128k           | 15                                     | 34%                              | 29%                                 | 5%                                            | 4%                     | 9%               | 42%                | 15%                              | 0%                         | -                                        | 1179          |
| Command-R (Mar '24)               | 128k           | 15                                     | 34%                              | 28%                                 | 5%                                            | 5%                     | 6%               | 40%                | 16%                              | 1%                         | -                                        | 1149          |
| Codestral-Mamba                   | 256k           | 14                                     | 21%                              | 21%                                 | 5%                                            | 13%                    | 11%              | 80%                | 24%                              | 0%                         | -                                        | -             |
| Mistral 7B                        | 8k              | 10                                     | 25%                              | 18%                                 | 4%                                            | 5%                     | 2%               | 40%                | 12%                              | 0%                         | -                                        | 1008          |
| Llama 3.2 1B                      | 128k           | 10                                     | 20%                              | 20%                                 | 5%                                            | 2%                     | 2%               | 40%                | 14%                              | 0%                         | -                                        | 1054          |
| Llama 2 Chat 7B                   | 4k              | 8                                      | 16%                              | 23%                                 | 6%                                            | 0%                     | 0%               | -                  | 6%                               | 0%                         | -                                        | 1037          |
